# â¤ï¸ Heart Disease Prediction ML Workflow

A production-style end-to-end machine learning pipeline for predicting heart disease using structured clinical data.
This project demonstrates a full ML workflow including data validation, EDA, feature engineering, model training, cross-validation, evaluation, and artifact generation.

Designed as a **portfolio-ready project** for Data Science / Machine Learning roles.

---

## ğŸš€ Project Overview

This project builds a machine learning system to predict whether a patient has heart disease based on clinical features such as age, cholesterol, ECG results, and more.

The workflow follows a **real-world ML pipeline structure**:

* Data validation
* Exploratory data analysis (EDA)
* Feature preprocessing pipeline
* Model comparison
* Cross-validation
* Final model training
* Evaluation & reporting
* Test prediction generation
* Saved model artifacts

The final system achieves strong predictive performance and is fully reproducible.

---

## ğŸ“Š Dataset

**Source:** Kaggle Playground Series
https://www.kaggle.com/competitions/playground-series-s6e2

* ~630,000 training samples
* 15 features (numerical + categorical)
* Binary target: **Heart Disease (0/1)**
* Well-balanced dataset (â‰ˆ55% vs 45%)

No heavy class imbalance handling required.

---

## ğŸ§  Key EDA Insights

**Strong predictors**

* ST depression (strong positive correlation)
* Max heart rate (strong negative correlation)
* Number of vessels (Fluro)
* Exercise-induced angina
* Thallium test results
* Chest pain type

**Moderate predictors**

* Age
* Cholesterol

**Weak predictor**

* Blood pressure (BP alone has limited predictive power)

Tree-based and linear models both perform well due to nonlinear relationships.

---

## ğŸ—ï¸ Project Structure

```
heart-disease-ml-workflow
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                # Paths & global config
â”‚   â”œâ”€â”€ data_validation.py       # Data quality checks
â”‚   â”œâ”€â”€ preprocessing.py         # Feature pipelines
â”‚   â”œâ”€â”€ train.py                 # Model training
â”‚   â”œâ”€â”€ evaluate.py              # Metrics & evaluation
â”‚   â”œâ”€â”€ cv.py                    # Cross-validation
â”‚   â”œâ”€â”€ predict_test.py          # Test prediction generation
â”‚   â”œâ”€â”€ main.py                  # Full pipeline entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ logreg_pipeline.pkl  # Saved trained model
â”‚   â”‚
â”‚   â””â”€â”€ reports/
â”‚       â”œâ”€â”€ run_summary.txt      # Training summary
â”‚       â””â”€â”€ test_predictions.csv # Predictions
â”‚
â”œâ”€â”€ eda.ipynb                    # Exploratory data analysis
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

* Python
* pandas / numpy
* scikit-learn
* joblib
* matplotlib / seaborn
* Jupyter Notebook

Focus: **production-style ML structure**, not just notebook modeling.

---

## ğŸ§ª Models Evaluated

| Model               | ROC-AUC    | Precision | Recall | F1     |
| ------------------- | ---------- | --------- | ------ | ------ |
| Logistic Regression | **0.9537** | 0.8553    | 0.8935 | 0.8740 |
| Random Forest       | 0.9477     | 0.8411    | 0.8945 | 0.8670 |

**Selected best model:** Logistic Regression
(based on validation ROC-AUC)

---

## ğŸ“ˆ Cross Validation (5-Fold)

```
ROC-AUC:   0.9529 Â± 0.0004
Precision: 0.8818 Â± 0.0005
Recall:    0.8599 Â± 0.0020
F1-score:  0.8707 Â± 0.0012
```

Model shows strong stability and generalization.

---

## ğŸ” Final Model Performance

* ROC-AUC: 0.9537
* F1-score: 0.8740
* Balanced precision/recall
* No severe overfitting
* Stable across folds

Model trained on full dataset and saved as reusable pipeline.

---

## â–¶ï¸ How to Run

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Run full pipeline

```bash
python src/main.py
```

This will:

* Validate data
* Train models
* Run cross-validation
* Evaluate performance
* Save best model
* Generate predictions
* Create run summary report

---

## ğŸ“ Outputs Generated

**Saved model**

```
src/models/logreg_pipeline.pkl
```

**Training summary**

```
src/reports/run_summary.txt
```

**Test predictions**

```
src/reports/test_predictions.csv
```

---

## ğŸ§© ML Engineering Highlights

This project demonstrates:

âœ” End-to-end ML pipeline design
âœ” Modular production-style structure
âœ” Config-driven paths
âœ” Feature preprocessing pipelines
âœ” Cross-validation workflow
âœ” Model comparison logic
âœ” Reproducible training
âœ” Artifact saving (model + reports)
âœ” Clean GitHub project organization

---

## ğŸš€ Future Improvements

* Add XGBoost / LightGBM models
* Hyperparameter tuning (Optuna/GridSearch)
* Model explainability (SHAP)
* FastAPI deployment
* Streamlit demo app
* Docker containerization

---

## ğŸ‘©â€ğŸ’» Author

Built as a machine learning portfolio project for data science and ML engineering roles.
